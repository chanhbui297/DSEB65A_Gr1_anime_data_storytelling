# üìò The Power of Data Preparation through Data Storytelling
---
## üìã README Structure
1. **Project Overview**: Short description & project structure  
2. **Dataset Description**: Source, size, features, raw vs. cleaned state, reason for choosing  
3. **Storytelling Context**: Business narrative & core message  
4. **Repository Structure**: Folder organization  
5. **Workflow (4-Phase Pipeline)**: Detailed phase-by-phase breakdown  
      Phase 1. Explore raw data problems: `jupyter notebook notebooks/01_Diagnostic_EDA.ipynb`
      Phase 2. Run data preparation: `jupyter notebook notebooks/02_Data_Preprocessing.ipynb`
      Phase 3. Compare visual narratives (Before and After Data Preparation): `jupyter notebook notebooks/03_Comparative_Analysis.ipynb`
      Phase 4. Validate with modeling: `jupyter notebook notebooks/04_Modeling_Comparison.ipynb`
 
6. **How to Run the Project**: Step-by-step execution guide  
7. **Key Findings & Conclusions**: Main insights & recommendations  
8. **License & References**

---

## üî• 1. Project Overview

This project demonstrates the **critical role of Data Preparation** in any Machine Learning workflow by using **data storytelling techniques**.  
Through a series of visual narratives and analytical comparisons, we highlight how *raw data vs. prepared data* drastically impacts:

- **Insight quality** and visualization accuracy
- **Business interpretations** and decision-making
- **Machine Learning performance** and model reliability

---

## üìä 2. Dataset Description

### **2.1. Dataset Overview**
**Dataset:** *Anime Dataset 2023 (Kaggle)*  
**Initial Size:** ~25,000 entries, 24+ features  
**Final Processed Size:** ~15,692 entries, 12 engineered features

---

### **2.2. Why We Chose This Dataset** 
- **Rich narrative potential**: Anime scoring involves multiple factors (creative, production, timing) - **Complex data structure**: Contains multi-label fields, inconsistent formats, and mixed data types 
- **Real-world relevance**: Represents common data challenges in entertainment/media analytics 
- **Clear before/after contrast**: Dramatic improvements possible through proper preprocessing 

---

### **2.3. Raw vs. Processed State**

#### üî∂ **Raw State (Before Cleaning)**
**Size:** *24,905 entries √ó 24 features*

**Critical Issues Identified**
- **37% missing scores (target variable)**
- **81% missing licensor information**
- **78% missing premiere dates**
- **20+ inconsistent date formats** across the dataset  
- **Hidden missing values:** ‚ÄúUnknown‚Äù, ‚Äú?‚Äù, ‚ÄúN/A‚Äù  
- **Logical conflicts:** *7,405 records have a ranking but no score*  
- **Type misclassification:**  
  - Movies listed with **>1 episode**  
  - TV series with **<10 minutes duration**  
- **Mixed data types** and unstructured multi-label fields (genres, studios, producers)

---

#### üî∑ **Processed State (After Cleaning)**
**Size:** *15,692 entries √ó 12 features*

**Quality Improvements**
- Removed structural inconsistencies  
- Resolved logical conflicts (ranking‚Äìscore mismatch, invalid episode counts, etc.)  
- Standardized all date formats + extracted **Aired Year** & **Aired Month**  
- Normalized multi-label categorical fields  
- Created reproducible **preprocessing pipeline**  
- Engineered **seasonal/cyclical features** for modeling  
- Established a clean, stable dataset for analysis & storytelling

---

### **2.4. Key Feature Groups**

---

## üìÅ **1. Basic Identification & Description**
- **anime_id** ‚Äì Unique identifier for each anime  
- **Name** ‚Äì Original Japanese title  
- **English name** ‚Äì Official English title  
- **Other name** ‚Äì Localized, alternative, or native titles  
- **Synopsis** ‚Äì Brief plot description  
- **Genres** ‚Äì Genre list (multi-label, comma-separated)  
- **Image URL** ‚Äì Anime thumbnail/poster URL  

---

## üé¨ **2. Production & Technical Details**
- **Type** ‚Äì TV / Movie / OVA / ONA / Special / Music  
- **Source** ‚Äì Manga / Light Novel / Original / Game / Web Manga / etc.  
- **Producers** ‚Äì Companies that funded or produced the anime  
- **Studios** ‚Äì Animation studios responsible for production  
- **Licensors** ‚Äì Companies licensing the anime (high missing rate)  
- **Episodes** ‚Äì Total episode count  
- **Duration** ‚Äì Runtime per episode (minutes)  

---

## üì° **3. Release & Airing Information**
- **Aired** ‚Äì Full airing period or release date  
- **Premiered** ‚Äì Season + Year (e.g., *Fall 2023*)  
- **Status** ‚Äì Finished / Currently Airing / Not Yet Aired  
- **Aired Year** ‚Äì Extracted release year  
- **Aired Month** ‚Äì Extracted release month (1‚Äì12)  

---

## ‚≠ê **4. Audience Engagement & Performance Metrics**
- **Score** ‚Äì Average user rating  
- **Rating** ‚Äì Age classification (PG-13, R, G‚Ä¶)  
- **Rank** ‚Äì Score-based ranking  
- **Popularity** ‚Äì Interaction-based popularity ranking  
- **Favorites** ‚Äì Count of users marking as favorite  
- **Scored By** ‚Äì Total number of user ratings  
- **Members** ‚Äì Total number of users adding the anime to their list  

---

## üé¨ 3. Storytelling Context & Business Narrative

**Business Context**: In the competitive Anime industry, understanding what drives high scores is crucial for producers, studios, and investors. However, raw anime data is notoriously messy ‚Äî containing inconsistent formats, missing values, and structural errors that obscure true patterns.

**Narrative Arc**: This project follows a detective-style story:
1. **The Problem**: Raw data shows confusing, misleading patterns
2. **The Investigation**: Systematic diagnosis reveals deep structural issues
3. **The Transformation**: Comprehensive cleaning and feature engineering
4. **The Revelation**: Clean data uncovers true drivers of success
5. **The Proof**: Quantifiable improvement in model performance

**Core Message**: Data Preparation isn't just technical cleanup ‚Äî it's the foundation that determines whether your analysis reveals truth or perpetuates misinformation.

---

## üìÅ 4. Repository Structure

```bash
anime-data-storytelling/
‚îÇ
‚îú‚îÄ‚îÄ .gitignore                  
‚îú‚îÄ‚îÄ README.md                           # Project overview (this file)
‚îú‚îÄ‚îÄ requirements.txt                    # Python dependencies
‚îÇ
‚îú‚îÄ‚îÄ data/   
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ anime-dataset-2023.csv  
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ       ‚îî‚îÄ‚îÄ prepared_data.csv   
‚îÇ
‚îú‚îÄ‚îÄ models/                              # Saved models & pipelines
‚îÇ ‚îú‚îÄ‚îÄ processing_pipeline.pkl                 # Data transformation pipeline
‚îÇ ‚îî‚îÄ‚îÄ model.pkl                               # Trained Linear Regression model
‚îÇ
‚îú‚îÄ‚îÄ src/                                 # Custom code
‚îÇ ‚îî‚îÄ‚îÄ Custom_Transformer.py                   # Custom transformers for anime data
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                           # Main analysis notebooks
‚îÇ ‚îú‚îÄ‚îÄ 01_Diagnostic_EDA.ipynb                 # Phase 1: Problem diagnosis
‚îÇ ‚îú‚îÄ‚îÄ 02_Data_Preprocessing.ipynb             # Phase 2: Data preparation
‚îÇ ‚îú‚îÄ‚îÄ 03_Comparative_Analysis.ipynb           # Phase 3: Visualization & insights
‚îÇ ‚îî‚îÄ‚îÄ 04_Modeling_Comparison.ipynb            # Phase 4: Model validation
‚îÇ
‚îú‚îÄ‚îÄ plots/                               # Generated visualizations
‚îÇ ‚îú‚îÄ‚îÄ 03_plots/                               # Exploratory charts
‚îÇ ‚îú‚îÄ‚îÄ 04_plots/                               # Clean data insights
‚îÇ ‚îî‚îÄ‚îÄ ML_Models/                              # Model comparison charts
‚îÇ
‚îî‚îÄ‚îÄ report/                               # Final Report
‚îî‚îÄ‚îÄ Final_Report_Group1.pdf                             

```

## üîÑ 5. Workflow (4-Phase Pipeline)

### **üìã PHASE 1 ‚Äî Diagnostic EDA ("The Data Doctor")**

### **1. Overview**
**Notebook:** `01_Diagnostic_EDA.ipynb`  
**Goal**: The primary purpose of Phase 1 is to **diagnose all data quality issues** that may distort analysis or produce misleading insights. This phase establishes the foundation for a reliable preprocessing pipeline.

---

### **2. Key Discoveries from Diagnostic EDA**

- **Type Mismatches**: Critical numeric columns (Score, Episodes, Rank) stored as strings

- **Hidden Missingness**: 
   - Instead of NaN, Missing values are stored as 'Unknown', 'not available', 'n/a', 'na', 'tbd', 'tba' 
   - All columns has missing values. Especially, Licensors has the highest pperrcentage of missing with over 80%. 

- **Skewed Distributions**: Engagement metrics (Members, Favorites) with 99th percentile outliers
- **Inconsistent Formating**: 
   - Datetime format: '1-Sep-01', 'Oct 20, 1999 to ?'
   - Durations: '3 min', '3 min per ep'

- **Multi-label in Genre, Producers, Studios**: ['Action','Sci-fi'] make it impossible for running model

- **Ghost Records**: 1,330 entries with zero engagement metrics and no metadata

- **Data Integrity and Misclassification in Type, Ratings, Duration, Episodes**: 
   - Movie with `Episodes > 1`, or Movies with less than 40 minutes
   - Labeled with Adult genre but has an All-Ages Rating 
   - Episode with Durations > 1000 minutes

- **Date Paradoxes**: 7 records with end dates before start dates

---

### **3. Conclusion**
Phase 1 confirms that the raw dataset is **not suitable for immediate analysis**.  Thus, a robust cleaning and transformation pipeline is required to ensure Structural consistency and Logical validity.  

This diagnostic stage sets the foundation for Phase 2: **Data Preparation & Pipeline Construction**.

---

### **üõ† PHASE 2 ‚Äî Data Preparation & Pipeline Construction**

### **1. Overview**
**Notebook:** `02_Data_Preprocessing.ipynb` and `Customtransformer.py` 

**Goal**: Build reproducible cleaning and transformation pipeline that handle issues stated in PHASE 1

**Outputs**:
- `data/processed/prepared_data.csv` (cleaned dataset)
- `models/processing_pipeline.pkl` (reusable pipeline)
- `models/model.pkl` (reusable Linear Regressor model)
- `src/Custom_Transformer.py` (custom class transformation used for pipeline)

---

### **2. Processing Steps**:

### **2.1. Pre-split cleaning (Structural Fixes Before Train/Test Split)**

### **A. Goal**  
Transform the raw file **`anime-dataset-2023.csv`** into a clean, structurally consistent dataset **`prepared_data.csv`**, ensuring:  
- Correct data types  
- Standardized formats  
- Unified representation for multi-label fields  
- Removal or correction of malformed entries

---

### **B. Critical Principle ‚Äî Why these steps MUST happen *before* splitting**

These operations address **structural and domain-logic corrections**, not statistical learning.  
Applying them post-split would produce inconsistent schemas between train/test.

| Reason | Explanation |
|--------|-------------|
| **1. Maintain structural consistency** | Fixing types, list formats, and date formats must apply to all rows. |
| **2. No learned parameters** | These operations do **not** compute statistics (mean, median, quantiles). |
| **3. Domain rules apply universally** | e.g., cleaning genres, standardizing format, converting data type 'object' to 'numeric' and 'datetime' |
| **4. Required for sklearn pipelines** | Downstream transformers expect consistent input schema. |

---

### **C. Main Steps (Structural Cleaning)**

**Step 1.  Standardize "NaN-like" Values**  
- **Strategy**: Many object columns use string literals to represent missing data. We'll replace them with np.NaN
- **Example**: ['unknown', 'not available', 'n/a', 'na', 'tbd', 'tba', '---'] -> NaN

**Step 2. Handle Placeholder Zeros**  
- **Strategy**: The values `0` in `Rank` and `Popularity` don't represent a true zero value but rather a missing or unassigned one. These should be converted to `np.nan`.

**Step 3. Standardize Formating in (Aired, Duration)**  
- **Strategy**: 
   - Extracting `Aired Month`, `Aired Year`, `Aired Date Start`, `Aired Date End` from `Aired` column
   - Convert string Duration (`24 min`) into single numeric value (`24.0`) 

**Step 4: Handle multi-lable columns (Genres, Studios, Producers)**
- **Strategy**: 
   - Split string value into proper list ('MAPPA, White Fox' -> ["MAPPA", "White Fox"])
   - Fixing Typo and Inconsistency using mapping: "Sunrise Inc." -> "Sunrise"

**Step 5: Data Type Coercion & Logic Validation**
- **Type conversion**: Strings like "8.75" ‚Üí float 8.75
- **Business rule fixes**: "Movie must have 1 episode" is domain knowledge, not learned from data
- **Ghost record removal**: Records with no score AND no metadata are fundamentally unusable

**Step 6: Drop Unnecessary Columns**

| **Feature Dropped** | **Reason for Dropping** |
|---------------------|--------------------------|
| **`Licensors`** | Missing over 80% of values ‚Üí unreliable for analysis/modeling |
| **`Premiered`** | 77% missing + redundant (information extracted from `Aired` into `air_year`, `air_month`) |
| **`English name`** | Redundant (primary `Name` column sufficient for identification) |
| **`Other name`** | Redundant (primary `Name` column sufficient for identification) |
| **`Image URL`** | Non-feature data (image links cannot be used in current analytical scope) |
| **`Synopsis`** | Requires NLP techniques beyond project scope; would distract from core analysis |
    
---

### **2.2.  Splitting X, y and Train, Test set**

### **A. Spliting Target Variable - `Score`**

```bash
X = df1.drop('Score', axis=1)
y = df1['Score']
```

### **B. Spliting Train and Test set (80/20)`**
```bash

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

```
The shape after splitting is:
   - X_train shape: (12553, 11), y_train ((12553, 1))
   - X_test shape: (3139, 11), y_test (3139, 1)  

---

### **2.3.  Post-Split Pipeline (Stateful Transformations)**

### **A. Goal**  
Produce final, fully processed Train/Test sets and store the fitted pipeline inside `models/` for use in  **PHASE 4 ‚Äî Modeling Comparison**.

---

### **B. Critical Principal**: 
- These operations learn statistical parameters from training data only, preventing data leakage and support reproducing for future uses.
- Since our main goal is to find out which feature contributing to a successful Anime Released, post-released features like `Rank`, `Members`, `Popularity`,`Favorites` and `Scored by` will be removed to **prevent casual data leakage** when predicting `Score` of an Anime.

--- 

### **C. Custom Transformers (Using `BaseEstimator` and `TransformerMixin`)**

--- 

   **C.1. Class MultiListModeImputer**: 
   - **Purpose**: Imputing multi-label columns (Genres, Studios, Producers)
   - **Strategy**: 
      - Aggregate all items and find the mode (most frequent label) based on **Train set**
      - Any missing / empty list in Train and Test set is replaced with [most_frequent_label]

---

   **C.2. Class FrequencyGrouper**: 
   - **Purpose**:  
      - Reduce high-cardinality categories before appling One-Hot-Encoder on (Genres, Studios, Producers)
      - Result: From **1,287 features** after OHE -> **231 features**
   - **Strategy**: 
      - Compute frequency of each label in Train split only
      - Keep labels with frequency ‚â• `min_freq[col]`
      - Replace all rare labels with "Other"

---

   **C.3. Class MultiLabelBinarizerDF** (Multi-Hot Encoding): 

   - **Purpose**:  
      - Transform list-like columns (Genres, Studios, Producers) into multi-hot encoded columns 

   - **Strategy**: 
      - Fit MultiLabelBinarizer per columns in Train
      - Transform/ Generate feature names: `ColumnName__Label` (example: `Genre_Action`)
      - Return concatenated DataFrame

--- 

   **C.4. CyclicalMonthEncoder**: 

   - **Purpose**: Convert months to sine/cosine features  
      - `Aired Month` are cyclical; month 12 is close to month 1, but ordinal encoding does not reflect this
      - Help model learn seasonality/ monthly patterns better

   - **Strategy**: 
      - Convert month numerics into sin/cos format: sin(2œÄ * month / 12), cos(2œÄ * month / 12)
      
--- 

   **C.5. FeatureEngineering**: 
   - **Purpose**:  
      - Add domain‚Äìrelevant features that models cannot automatically create.

   - **Strategy**: 
      - Interaction terms:  `Episodes_x_Duration Minutes` help capturing combined effects on Score
      - Quantile-based categorization using `pd.cut()`: Created `DurationCat` and `EpisodesCat` features to capture non-linear relationships specific to anime formats and type (Movie is has only 1 episode and usually very long) 

      
--- 

### **D. Sklearn Library: Functions, Classes, and Rationale**
--- 

   **D.1.  Power Transformation - learns lambda parameter from Train only**: 
   - **Purpose**:  
      - Normalize highly skewed numeric columns
      - Suitable for Lineae Model

   - **Strategy**: 
      - Using Yeo-Johnson to handles zero (Counting_feature has 0 values)
      
--- 

   **D.2. SimpleImputer (median, mode) - learns values from Train only**: 
   - **Strategy**:  
      - Median ‚Üí for numeric columns
      - Most Frequent (mode) ‚Üí for categorical columns

   - **Reasons**: 
      - Robust to outliers, best choice when distributions are skewed

--- 

   **D.3. Scaling (RobustScaler) - learns quantiles from Train only**: 
   - **Strategy**:  
      - Uses median and IQR, not mean & std. 

   - **Reasons**: 
      - Dataset contains extreme outliers (e.g., 10,000+ episode counts for special cases) 
      - Resistant to heavy-tailed distributions

--- 

   **D.4. Encoding (OneHot, MultiHot) - learns categories from Train only**: 
   - **Strategy**:  
      - handle_unknown="ignore" prevents crash on unseen categories
      - Learns category vocabulary from train only

   - **Reasons**: 
      - **One-Hot Encoding**: Handle categorical features like Rating, DurationCat, EpisodesCat.
      - **Multi-Hot Encoding**: sklearn‚Äôs OHE cannot handle list-of-labels
       
--- 

   **D.5. ColumnTransformer**: 
   - **Strategy**:  
      - There are 4 sub-pipeline used for 4 groups of features 
      - 4 groups of features: Numeric, Ordinal Category, Multi-Lable Category, Cyclical features

   - **Reasons**: 
      - Apply different transformations to different feature groups.

--- 

### **E. Building Pipeline**
The `prepocessing_pipeline.pkl` has 2 sub-pipeline: `Feature Engineering Pipeline` and `Preprocessor Pipeline` as follows

```bash
Full Pipeline  
‚îÇ                   
‚îî‚îÄ‚îÄ Sub_Pipe_1 - Feature Engineering 
‚îÇ     ‚îú‚îÄ‚îÄ  Create_interactions
‚îÇ     ‚îú‚îÄ‚îÄ  Create_list_counts
‚îÇ     ‚îú‚îÄ‚îÄ  Discretization_Duration
‚îÇ     ‚îî‚îÄ‚îÄ  Discretization_Episode
‚îÇ
‚îÇ
‚îî‚îÄ‚îÄ Sub_Pipe_2 - Preprocessor       # Using ColumnTransformer
   ‚îÇ
   ‚îú‚îÄ‚îÄ Numerical Pipeline           # ['Episodes','Duration Minutes','Aired Year',
   ‚îÇ   ‚îÇ                            # 'Episodes_x_Duration Minutes','Genres_Count','Producers_Count','Studios_Count']
   ‚îÇ   ‚îú‚îÄ‚îÄ Median Imputer
   ‚îÇ   ‚îú‚îÄ‚îÄ PowerTransformer
   ‚îÇ   ‚îî‚îÄ‚îÄ RobustScaler
   ‚îÇ
   ‚îú‚îÄ‚îÄ Categorical Pipeline        # ['Type','Status','Source','Rating','EpisodesCat','DurationCat'] 
   ‚îÇ   ‚îú‚îÄ‚îÄ Mode Imputer
   ‚îÇ   ‚îú‚îÄ‚îÄ Frequency Grouper
   ‚îÇ   ‚îî‚îÄ‚îÄ OneHotEncoder
   ‚îÇ
   ‚îú‚îÄ‚îÄ Multi-label Pipeline         # ['Genre','Producers','Studios']
   ‚îÇ   ‚îú‚îÄ‚îÄ MultiListModeImputer
   ‚îÇ   ‚îú‚îÄ‚îÄ Frequency Grouper
   ‚îÇ   ‚îî‚îÄ‚îÄ MultiHotEncoder
   ‚îÇ
   ‚îî‚îÄ‚îÄ  Date Pipeline                # ['Aired Month']
       ‚îî‚îÄ‚îÄ CyclicalMonthEncoder

```


--- 

### **üìà PHASE 3 ‚Äî Comparative Analysis ("Before vs After")**

### **1. Overview**

**Notebook:** `03_Comparative_Analysis.ipynb`  

**Goal**: Visualize how clean data changes the narrative and support the keys to a successful anime

**Workflow**: This phase has 3 main Action

--- 

1. ACT 1 - THE SITUATION:
   - **Role**: Producer seeking the success formula for the next Anime project
   - **Goal**: Identify factors with strongest impact on Score
   - **The Conflict**: Raw data (df_raw) is chaotic, unusable for decision-making

---

2. ACT 2 - THE COMPLICATION & DISCOVERY
- Each Theme will have 4 main steps: Issues Overview -> Solutions -> Visual Evidence (Raw vs Cleaned) -> Deeper Visual Analysis for Business Recommendation
- The 4 main Theme Feature:  
      - Theme A: Target Variable (Score)
      - Theme B: Market Factors (Type, Source)
      - Theme C: Creative Factors (Genres, Producers, Studios)
      - Theme D: Release Strategy (Aired, Episodes, Duration)

---

3. ACT 3: THE RESOLUTION
      - Proof: Model performance comparison 
      - Strategic Recommendation for Producer
      - Takeaway: "Success is engineered through data-informed decisions"

---

### **2. Key Findings**

---

#### **Act 1: The Foundation: Target Variable Analysis (Score)**
   - **Issue Overview**: 37% missing scores, stored as text, distribution skewed by placeholder values

   - **Solution**: Remove missing, convert to numeric, validate logical consistency
   
   - **Visual Evidence**:
      - Raw: Bimodal distribution with artificial "0" peak
      - Clean: Normal distribution centered at 6.39, revealing true quality spectrum
   
   - **Conclusion**: 
      - *The actual `Score` distribution is bell-shape -> no need for transformation
      - *True high-scoring animes (Score >8.5) are rare, not artificially common*

---

#### **Act 2: The Complications & Discovery**

--- 

**A. Theme A: Market Factors (Type, Source)**
   - **Issue Overview**: Type misclassification (Movie with >1 episode), Source fragmentation (16 micro-categories), Unknown value

   - **Solution**: Reclassification logic, macro-categorization (5 groups)

   - **Visual Evidence**:
      - Raw: Misleading "OVA" dominance due to misclassified Movies
      - Clean: True distribution: OVA (6,062) > TV (5,511) > Special (3,673)

   - **Business Insight**: 
      - *TV series and Monvies have highest average Score (7.1)*
      - *Producers should prioritize source from **Manga or Literary properties** for maximizing Score*

---

**B. Theme B: Creative & Production Factors (Genres, Producers, Studios)**
   - **Issue Overview**: Multi-label fragmentation, high cardinality, inconsistent naming, Unknow value

   - **Solution**: Frequency grouping, name normalization

   - **Visual Evidence**:
      - Raw: "Sunrise Inc.", "Sunrise", "Sunrise Studios" treated as separate
      - Clean: Consolidated to single entity, revealing true market share

   - **Business Insight**: 
      - *Which Genres do top Studios consistently excel in, helping Producer decide on hiring Studio decision (example: White Fox Studio did best on Romance and Mystery)*

---

**C. Theme C: Release Strategy (Aired, Episodes, Duration)**
   - **Issue Overview**: Numeric, Datetime feature treated as text, fragmentation, high cardinality, inconsistent format, Unknow value

   - **Solution**: Convert to numeric, datetime type; Normalize format, Grouping into meaningful Episodes, Duration ranges and seasons

   - **Visual Evidence**:
      - Raw: Random monthly distribution, inconsistent format "3 min", "3 min per ep"
      - Clean: ordered monthly distribution, meaningful groups of episodes and duration ranges

   - **Business Insight**: 
      -  *12-13 episode format with over 60 minute runtime maximizes both Score and engagement*
      -  *Apr, Jul, Oct are the hot-month for releasing new anime*


--- 
### **‚öñÔ∏è PHASE 4 ‚Äî Modeling Comparison ("The Validator")**

### **1. Overview**
**Notebook:** `04_Modeling_Comparison.ipynb`  

**Goal**: Quantify the impact of data preparation via ML performance

**Methodology**:
1. **Baseline Model**: Linear Regression on minimally processed raw data
2. **Final Model**: Same algorithm on fully prepared data
3. **Comparison**: Metrics (R¬≤, MAE) and feature importance analysis

---

### **2. Metrics Results**:
| Metric | Baseline (Raw Data) | Final (Prepared Data) | Improvement |
|--------|-------------------|---------------------|-------------|
| **R¬≤ Score** | 0.09 | 0.53 | **+443%** |
| **MAE** | 0.64 | 0.48 | **-24%** |


---

### **3. Feature Importance Shift**:
- **Baseline**: Weak signals from Status, Rating, Source
- **Final**: Strong signals from Producers, Studios, Genres (properly encoded)
- **Insight**: Preparation unlocks the true predictive power of categorical features

---

## ‚öôÔ∏è 6. How to Run the Project

### **Step 1 ‚Äî Clone Repository**
```bash
git clone https://github.com/<your-username>/anime-data-storytelling.git
cd anime-data-storytelling
```

### **Step 2 ‚Äî Install Dependencies**

Install required Python packages:
```bash
pip install -r requirements.txt
``` 

Note: If you prefer using a virtual environment:
```bash
# Create virtual environment
python -m venv venv

# Activate on Windows:
venv\Scripts\activate

# Activate on macOS/Linux:
source venv/bin/activate

# Then install dependencies
pip install -r requirements.txt
```

### **Step 3 ‚Äî Run Analysis Pipeline**

Execute notebooks in sequential order:
1. Explore raw data problems: `jupyter notebook notebooks/01_Diagnostic_EDA.ipynb`
2. Run data preparation: `jupyter notebook notebooks/02_Data_Preprocessing.ipynb`
3. Compare visual narratives (Before and After Data Preparation): `jupyter notebook notebooks/03_Comparative_Analysis.ipynb`
4. Validate with modeling: `jupyter notebook notebooks/04_Modeling_Comparison.ipynb`

### **Step 4 ‚Äî Generate All Visualizations**

All charts are automatically saved to the `plots/` directory when running notebooks 03 and 04.

### **Step 5 ‚Äî Reading the Final Report**
After running all notebooks, the final synthesized report is available as a PDF in the `report/Final_Report_Group1.pdf` directory

---
## üìà 7. Key Findings & Conclusions

### **7.1. Data Preparation Impact**
1. **Visual Clarity**: Cleaned data reveals true patterns obscured by noise
2. **Business Insights**: Actionable recommendations emerge only after preparation
3. **Model Performance**: R¬≤ improved from **0.09 to 0.53** (443% increase)
4. **Feature Understanding**: Proper encoding reveals true drivers (Producers, Studios)

### **7.2. Storytelling Principles Applied**
- **Contrast**: Clear before/after comparisons
- **Focus**: Highlight most impactful transformations
- **Narrative Flow**: Problem ‚Üí Solution ‚Üí Visual Evidence ‚Üí Business Recommendation
- **Audience Alignment**: Technical proof + business relevance

### **7.3. Strategic Recommendations for Anime Industry**
Based on cleaned data analysis:
1. **Production Strategy**: Focus on 12-13 episode formats with established studios
2. **Release Timing**: Target seasonal windows (January, April, July, October)
3. **Creative Mix**: Combine popular genres (Action √ó Fantasy, Comedy √ó Slice-of-life)
4. **Quality Signals**: Partner with top producers and studios as quality proxies

---

## üìÑ 8. License & References

**License**: MIT  
**Dataset Source**: [Kaggle - Anime Dataset 2023](https://www.kaggle.com/datasets/dbdmobile/myanimelist-dataset)

**Key References**:
- Knaflic, C. N. (2015). *Storytelling with Data*
- McKinney, W. (2017). *Python for Data Analysis*
- Scikit-learn documentation for pipeline design

---

**Project Status**: ‚úÖ Complete  
**Last Updated**: December 2024

*This project demonstrates that in data science, the quality of your preparation determines the quality of your insights.*